{
  "cells": [
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "# AgentQnA vLLM Deployment and Performance Evaluation Tutorial\n",
     "\n",
     "## Table of Contents\n",
     "1. [Overview](#overview)\n",
     "2. [Prerequisites](#prerequisites)\n",
     "3. [System Architecture](#system-architecture)\n",
     "4. [Deployment Guide](#deployment-guide)\n",
     "5. [Performance Evaluation](#performance-evaluation)\n",
     "6. [Monitoring and Troubleshooting](#monitoring-and-troubleshooting)\n",
     "7. [Advanced Configuration](#advanced-configuration)\n",
     "8. [Troubleshooting](#troubleshooting)\n",
     "\n",
     "---"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "## Overview\n",
     "\n",
     "AgentQnA is a Retrieval-Augmented Generation (RAG) system that combines document retrieval with LLM inference for agent-based applications. This tutorial provides a comprehensive guide for deploying AgentQnA using vLLM on AMD GPUs with ROCm support, and performing pipeline performance evaluation.\n",
     "\n",
     "### Key Features\n",
     "- **vLLM Integration**: LLM serving with optimized inference on AMD Instinct GPUs\n",
     "- **AMD GPU Support**: ROCm-based GPU acceleration\n",
     "- **Vector Search**: Redis-based document retrieval\n",
     "- **Agent Pipeline**: Complete agent-based question-answering system\n",
     "- **Performance Monitoring**: Built-in metrics and evaluation tools"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "## Prerequisites\n",
     "\n",
     "- **AMD Developer Cloud**: 1xMI300X GPU / 192 GB VRAM / 20 vCPU / 240 GB RAM Droplet\n",
     "- **Hugging Face Token**: For model access\n",
     "- **LangChain API Key**: For LangChain integration"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "## System Architecture\n",
     "\n",
     "### Service Components\n",
     "\n",
     "The following is the complete system architecture diagram.\n",
     "\n",
     "**Architecture Overview:**\n",
     "```\n",
     "┌───────────────────────────────────────────────────────────────────────────────────┐\n",
     "│                               EXTERNAL ACCESS                                     │\n",
     "│                                                                                   │\n",
     "│   ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────────────────┐   │\n",
     "│   │   Web Browser   │    │   API Clients   │    │      Monitoring Tools       │   │\n",
     "│   │                 │    │                 │    │    (Grafana, Prometheus)    │   │\n",
     "│   └─────────────────┘    └─────────────────┘    └─────────────────────────────┘   │\n",
     "│           │                       │                           │                   │\n",
     "│           │                       │                           │                   │\n",
     "│           ▼                       ▼                           ▼                   │\n",
     "│   ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────────────────┐   │\n",
     "│   │   Nginx Proxy   │    │   Backend API   │    │        Redis Insight        │   │\n",
     "│   │   (Port 8081)   │    │   (Port 8890)   │    │         (Port 8002)         │   │\n",
     "│   └─────────────────┘    └─────────────────┘    └─────────────────────────────┘   │\n",
     "│           │                       │                           │                   │\n",
     "│           │                       │                           │                   │\n",
     "│           ▼                       ▼                           ▼                   │\n",
     "│   ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────────────────┐   │\n",
     "│   │   Frontend UI   │    │     Backend     │    │   Redis Vector Database     │   │\n",
     "│   │   (Port 5174)   │    │     Server      │    │         (Port 6380)         │   │\n",
     "│   │   (React App)   │    │    (FastAPI)    │    │      (Vector Storage)       │   │\n",
     "│   └─────────────────┘    └─────────────────┘    └─────────────────────────────┘   │\n",
     "│                                   │                           │                   │\n",
     "│                                   │                           │                   │\n",
     "│                                   ▼                           ▼                   │\n",
     "│  ┌─────────────────────────────────────────────────────────────────────────────┐  │\n",
     "│  │                             AGENT PIPELINE                                  │  │\n",
     "│  │                                                                             │  │\n",
     "│  │  ┌───────────────────┐ ┌─────────────────────┐ ┌─────────────────────────┐  │  │\n",
     "│  │  │ Retriever Service │ │TEI Embedding Service│ │  TEI Reranking Service  │  │  │\n",
     "│  │  │                   │ │                     │ │                         │  │  │\n",
     "│  │  │   (Port 7001)     │ │    (Port 18091)     │ │      (Port 18809)       │  │  │\n",
     "│  │  │                   │ │                     │ │                         │  │  │\n",
     "│  │  │ • Vector Search   │ │ • Text Embedding    │ │ • Document Reranking    │  │  │\n",
     "│  │  │ • Similarity      │ │ • BGE Model         │ │ • Relevance Scoring     │  │  │\n",
     "│  │  │   Matching        │ │ • CPU Inference     │ │ • CPU Inference         │  │  │\n",
     "│  │  └───────────────────┘ └─────────────────────┘ └─────────────────────────┘  │  │\n",
     "│  │            │                      │                         │               │  │\n",
     "│  │            │                      │                         │               │  │\n",
     "│  │            ▼                      ▼                         ▼               │  │\n",
     "│  │  ┌───────────────────┐ ┌─────────────────────┐ ┌─────────────────────────┐  │  │\n",
     "│  │  │ RAG Agent Service │ │ SQL Agent Service   │ │ React Agent Service     │  │  │\n",
     "│  │  │   (Port 9095)     │ │    (Port 9096)      │ │      (Port 9090)        │  │  │\n",
     "│  │  │ • Document        │ │ • SQL Query         │ │ • React Pattern         │  │  │\n",
     "│  │  │   Processing      │ │ • Database          │ │ • UI Integration        │  │  │\n",
     "│  │  │ • Action          │ │ • Optimization      │ │ • State Management      │  │  │\n",
     "│  │  │   Planning        │ │ • Query             │ │ • User Interaction      │  │  │\n",
     "│  │  │ • Tool Usage      │ │   Generation        │ │ • Response              │  │  │\n",
     "│  │  └───────────────────┘ └─────────────────────┘ └─────────────────────────┘  │  │\n",
     "│  └─────────────────────────────────────────────────────────────────────────────┘  │\n",
     "│                                      │                                            │\n",
     "│                                      │                                            │\n",
     "│                                      ▼                                            │\n",
     "│  ┌─────────────────────────────────────────────────────────────────────────────┐  │\n",
     "│  │                            DATA PIPELINE                                    │  │\n",
     "│  │                                                                             │  │\n",
     "│  │  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────────────┐  │  │\n",
     "│  │  │   Dataprep      │    │   Model Cache   │    │   Document Storage      │  │  │\n",
     "│  │  │   Service       │    │   (./data)      │    │   (Redis Vector DB)     │  │  │\n",
     "│  │  │   (Port 18104)  │    │                 │    │                         │  │  │\n",
     "│  │  │                 │    │ • Downloaded    │    │ • Vector Embeddings     │  │  │\n",
     "│  │  │ • Document      │    │   Models        │    │ • Metadata Index        │  │  │\n",
     "│  │  │   Processing    │    │ • Model Weights │    │ • Full-Text Search      │  │  │\n",
     "│  │  │ • Text          │    │ • Cache Storage │    │ • Similarity Search     │  │  │\n",
     "│  │  │   Extraction    │    │ • Shared Volume │    │ • Redis Stack           │  │  │\n",
     "│  │  └─────────────────┘    └─────────────────┘    └─────────────────────────┘  │  │\n",
     "│  └─────────────────────────────────────────────────────────────────────────────┘  │\n",
     "└───────────────────────────────────────────────────────────────────────────────────┘\n",
     "```\n",
     "**Additional Services:**\n",
     "- **Dataprep Service** (Port 18104): Document processing and ingestion\n",
     "- **Redis Insight** (Port 8002): Database monitoring interface\n",
     "- **Model Cache** (./data): Shared volume for model storage\n",
     "\n",
     "### Data Flow\n",
     "1. **User Input**: Question submitted via frontend\n",
     "2. **Embedding**: Question converted to vector using TEI service\n",
     "3. **Retrieval**: Similar documents retrieved from Redis vector database\n",
     "4. **Reranking**: Retrieved documents reranked for relevance\n",
     "5. **LLM Inference**: vLLM generates answer using retrieved context\n",
     "6. **Response**: Answer returned to user via frontend"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "## Deployment Guide\n",
     "\n",
     "### Step 1: Pull source code from GitHub"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Open Platform for Enterprise AI (OPEA)\n",
     "!git clone https://github.com/opea-project/GenAIExamples.git"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# One click deployment scripts for the use case\n",
     "!git clone https://github.com/Yu-amd/LaunchPad.git"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "The LaunchPad project uses the same hierarchy as OPEA project. You need to copy the scripts and yaml files from the directory:  to the corresponding directory in OPEA folder:"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Copy necessary scripts and configuration files to the OPEA directory\n",
     "# Replace /path/to/OPEA repos with your actual OPEA path\n",
     "!cp LaunchPad/GenAIExamples/AgentQnA/docker_compose/amd/gpu/rocm/*.sh /path/to/GenAIExamples/AgentQnA/docker_compose/amd/gpu/rocm/\n",
     "!cp LaunchPad/GenAIExamples/AgentQnA/docker_compose/amd/gpu/rocm/*.yaml /path/to/GenAIExamples/AgentQnA/docker_compose/amd/gpu/rocm/"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 2: Setup environment"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Setup environment\n",
     "./run_agentqna.sh setup-vllm"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 3: Start services"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Start services\n",
     "./run_agentqna.sh start-vllm"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 4: Evaluate performance"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Evaluate performance\n",
     "./run_agentqna.sh vllm-eval"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 5: Compare performance"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Compare performance\n",
     "./run_agentqna.sh compare-eval"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 6: Monitor performance"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Monitor performance\n",
     "./run_agentqna.sh monitor-start"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 7: Stop services"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Stop services\n",
     "./run_agentqna.sh stop-vllm"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 8: Cleanup"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Cleanup\n",
     "./run_agentqna.sh cleanup"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 9: Monitor performance"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Monitor performance\n",
     "./run_agentqna.sh monitor-start"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 10: Stop services"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Stop services\n",
     "./run_agentqna.sh stop-vllm"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 11: Cleanup"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Cleanup\n",
     "./run_agentqna.sh cleanup"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 12: Monitor performance"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Monitor performance\n",
     "./run_agentqna.sh monitor-start"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 13: Stop services"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Stop services\n",
     "./run_agentqna.sh stop-vllm"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 14: Cleanup"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Cleanup\n",
     "./run_agentqna.sh cleanup"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 15: Monitor performance"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Monitor performance\n",
     "./run_agentqna.sh monitor-start"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 16: Stop services"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Stop services\n",
     "./run_agentqna.sh stop-vllm"
    ]
   },
   {
    "cell_type": "markdown",
    "execution_count": null,
    "metadata": {},
    "source": [
     "### Step 17: Cleanup"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {}
   }
  ]